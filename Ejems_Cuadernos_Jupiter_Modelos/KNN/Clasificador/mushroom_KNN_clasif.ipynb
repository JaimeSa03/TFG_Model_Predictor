{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e23e12",
   "metadata": {},
   "source": [
    "# Ejmplo perceptron multicapa para clasificacion\n",
    "### Examen Mayo 2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff0e6e6",
   "metadata": {},
   "source": [
    "## Librerias y carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67756c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# Cargar datos\n",
    "df = pd.read_csv('mushroom.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b5cf79",
   "metadata": {},
   "source": [
    "## Limpieza de los Datos con Funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae91a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes antes de la limpieza:\n",
      " cap-diameter       2\n",
      "cap-shape          0\n",
      "gill-attachment    0\n",
      "gill-color         0\n",
      "stem-height        0\n",
      "stem-width         2\n",
      "stem-color         0\n",
      "season             0\n",
      "class              0\n",
      "dtype: int64\n",
      "Valores faltantes después de la limpieza:\n",
      " 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "dtype: int64\n",
      "Train shape: (43228, 8)\n",
      "Test  shape: (10807, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def clean_and_split2(df: pd.DataFrame,\n",
    "                    col_objetivo: str,\n",
    "                    test_size: float = 0.2,\n",
    "                    random_state: int = 13):\n",
    "    \n",
    "    # Contar NaNs antes de limpiar\n",
    "    nan_counts_before = df.isna().sum()  # cuenta de valores faltantes por col\n",
    "    print(\"Valores faltantes antes de la limpieza:\\n\", nan_counts_before)\n",
    "\n",
    "    # Se eliminan todas las filas que contienen al menos un valor nulo\n",
    "    #df = df.dropna(how='any') \n",
    "    \n",
    "    # 1. Extraer la col objetivo del resto de las características del DF, separar X e y\n",
    "    y = df[col_objetivo].values  # objetivo como array numpy\n",
    "    X = df.drop(columns=[col_objetivo])  # elimina la col objetivo\n",
    "\n",
    "    # 2. Separar entre columnas numéricas y categoricas\n",
    "    numeric_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categoric_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # 3. Definir pipeline para porcesar cols numericas\n",
    "    # Vamos a quitar los NaN y una normalizacion a 0-1\n",
    "    numeric_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # sustituye NaN por media\n",
    "        ('scaler', MinMaxScaler())  # normaliza valores al rango [0,1]\n",
    "    ])\n",
    "\n",
    "    # 4. Definir pipeline para porcesar cols categoricas\n",
    "    # Vamos a quitar los NaN y hacer codificaion OneHot\n",
    "    categoric_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # sustituye NaN por moda\n",
    "        ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))  # codifica categorias, OneHot\n",
    "    ])\n",
    "\n",
    "    # 5. Combinar los pipelines en el prepocesor\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_pipeline, numeric_cols),  # aplica a num_cols\n",
    "        ('cat', categoric_pipeline, categoric_cols)   # aplica a cat_cols\n",
    "    ])\n",
    "\n",
    "    # 6. Ajustar transformaciones y transformar datos\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "    # Contar NaNs despues de la limpieza (ya no deberia haber)\n",
    "    # DataFrame temporal para comprobalo\n",
    "    nuevo_df = pd.DataFrame(X_processed)\n",
    "    nan_cont_desp = nuevo_df.isna().sum()\n",
    "    print(\"Valores faltantes después de la limpieza:\\n\", nan_cont_desp)\n",
    "\n",
    "    # 7. Division en train y test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_processed, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "#Utilizamos la funcion para obtener los datos de entrenamiento y test\n",
    "col_objetivo = \"class\"\n",
    "X_train, X_test, y_train, y_test = clean_and_split2(df, col_objetivo)\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test  shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a7a621",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc35d006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN: 0.9887110206347738\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Instanciar KNN con k=5 vecinos \n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Entrenar modelo\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predecir sobre el conjunto de test\n",
    "y_predict_KNN = clf.predict(X_test)\n",
    "\n",
    "# Calcular accuracy\n",
    "ac = accuracy_score(y_predict_KNN, y_test)\n",
    "print(\"Accuracy KNN:\", ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21022f5",
   "metadata": {},
   "source": [
    "## Mostrar resultados:\n",
    "### Matriz de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e8d162e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion MLP:\n",
      "[[4806   67]\n",
      " [  55 5879]]\n",
      "\n",
      "Falsos positivos KNN: 67\n",
      "\n",
      "Falsos negativos KNN: 55\n",
      "\n",
      "Accuracy 0.9887110206347738\n",
      "\n",
      "precision_score 0.9887319206189035\n",
      "\n",
      "recall_score 0.9907313784967982\n",
      "\n",
      "f1_score 0.9897306397306397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "cm_KNN = confusion_matrix(y_test, y_predict_KNN)\n",
    "print(\"Matriz de confusion MLP:\")\n",
    "print(cm_KNN)\n",
    "# (0,0) TN: Verdaderos negativos\n",
    "# (0,1) FP: Falsos positivos (¡esto es lo que quieres!)\n",
    "# (1,0) FN: Falsos negativos\n",
    "# (1,1) TP: Verdaderos positivos\n",
    "\n",
    "fp_knn = cm_KNN[0, 1]\n",
    "fn_knn = cm_KNN[1, 0]\n",
    "print(\"\\nFalsos positivos KNN:\", fp_knn)\n",
    "print(\"\\nFalsos negativos KNN:\", fn_knn)\n",
    "\n",
    "'''\n",
    "Cuándo priorizar cada una:\n",
    "\n",
    "    Si te preocupan FP (falsos positivos), examina precision.\n",
    "\n",
    "    Si temes mas FN (falsos negativos), mira recall.\n",
    "\n",
    "    El F1-score equilibra ambas.\n",
    "'''\n",
    "acc = accuracy_score(y_test, y_predict_KNN)\n",
    "print(\"\\nAccuracy\",ac) #ya lo muestro antes al hacer el modelo\n",
    "prec = precision_score(y_test, y_predict_KNN)\n",
    "print(\"\\nprecision_score\",prec)\n",
    "rec = recall_score(y_test, y_predict_KNN)\n",
    "print(\"\\nrecall_score\",rec)\n",
    "f1 = f1_score(y_test, y_predict_KNN)\n",
    "print(\"\\nf1_score\",f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709c5f4a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
